{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W207 Final Project Yu_ Zhu_ Lam.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PMhwZJBHZyCz"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tOphhU8lrej"
      },
      "source": [
        "## OpenVaccine: COVID-19 mRNA Vaccine Degradation Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnqSDG-RtOWE"
      },
      "source": [
        "Our team is interested in tackling the OpenVaccine Kaggle competition (https://www.kaggle.com/c/stanford-covid-vaccine) by developing a neutrual network model to predict COVID-19 mRNA vaccine degradation. Train set provides 2400 RNA sequences, and each sequence has three RNA structure features (structure, reactivity, predicted loop type) and five ground truths that evaluated through experiments (deg_pH10, deg_Mg_pH10, deg_50C, deg_Mg_50C, reactivity) and their correponding errors. The goal of this competiton is to use RNA structural features to predict the degradation rates at each base of RNA sequence at three experimental conditions, including reactivity, deg_Mg_pH10, and deg_Mg_50C.\n",
        "\n",
        "The additional challenge is problem in this exercise is the different size of training and testing target. We have decided to focus on the public test (see below) to simply the issue. If time permits, we will look to address the bigger sized target prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsCOhmCltlqv"
      },
      "source": [
        "### Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4cYnkmN2EHA"
      },
      "source": [
        "# This tells matplotlib not to try opening a new window for each plot.\n",
        "%matplotlib inline\n",
        "\n",
        "# General libraries.\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# SK-learn libraries for learning.\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "\n",
        "# SK-learn library for importing the newsgroup data.\n",
        "\n",
        "# SK-learn libraries for feature extraction from text.\n",
        "from sklearn.feature_extraction.text import *\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import nltk\n",
        "\n",
        "# Tools for counting letters in the sequences\n",
        "from collections import Counter as count\n",
        "import plotly.express as px\n",
        "\n",
        "# import tenserflow for neural network models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout, LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIiq1g_GZfh8"
      },
      "source": [
        "### Mounting Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2kpYO_Z4kqr",
        "outputId": "0dbabab4-1278-4df8-e19d-c60212bd50dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paU8tT5NZR2F"
      },
      "source": [
        "### Load the train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "IQubGQsNltFG",
        "outputId": "ce9076c0-e35d-49a6-c566-3c380ef86b93"
      },
      "source": [
        "# full_train = pd.read_json('/content/drive/MyDrive/1 MIDS/W207 Applied Machine Learning/Final Project/train.json', lines=True)\n",
        "full_train = pd.read_json('/content/drive/MyDrive/Final Project/train.json', lines=True)\n",
        "full_train = full_train.set_index(keys='index')\n",
        "full_train.info()\n",
        "full_train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2400 entries, 0 to 2399\n",
            "Data columns (total 18 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   id                   2400 non-null   object \n",
            " 1   sequence             2400 non-null   object \n",
            " 2   structure            2400 non-null   object \n",
            " 3   predicted_loop_type  2400 non-null   object \n",
            " 4   signal_to_noise      2400 non-null   float64\n",
            " 5   SN_filter            2400 non-null   int64  \n",
            " 6   seq_length           2400 non-null   int64  \n",
            " 7   seq_scored           2400 non-null   int64  \n",
            " 8   reactivity_error     2400 non-null   object \n",
            " 9   deg_error_Mg_pH10    2400 non-null   object \n",
            " 10  deg_error_pH10       2400 non-null   object \n",
            " 11  deg_error_Mg_50C     2400 non-null   object \n",
            " 12  deg_error_50C        2400 non-null   object \n",
            " 13  reactivity           2400 non-null   object \n",
            " 14  deg_Mg_pH10          2400 non-null   object \n",
            " 15  deg_pH10             2400 non-null   object \n",
            " 16  deg_Mg_50C           2400 non-null   object \n",
            " 17  deg_50C              2400 non-null   object \n",
            "dtypes: float64(1), int64(3), object(14)\n",
            "memory usage: 356.2+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sequence</th>\n",
              "      <th>structure</th>\n",
              "      <th>predicted_loop_type</th>\n",
              "      <th>signal_to_noise</th>\n",
              "      <th>SN_filter</th>\n",
              "      <th>seq_length</th>\n",
              "      <th>seq_scored</th>\n",
              "      <th>reactivity_error</th>\n",
              "      <th>deg_error_Mg_pH10</th>\n",
              "      <th>deg_error_pH10</th>\n",
              "      <th>deg_error_Mg_50C</th>\n",
              "      <th>deg_error_50C</th>\n",
              "      <th>reactivity</th>\n",
              "      <th>deg_Mg_pH10</th>\n",
              "      <th>deg_pH10</th>\n",
              "      <th>deg_Mg_50C</th>\n",
              "      <th>deg_50C</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_001f94081</td>\n",
              "      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n",
              "      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n",
              "      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n",
              "      <td>6.894</td>\n",
              "      <td>1</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n",
              "      <td>[0.26130000000000003, 0.38420000000000004, 0.1...</td>\n",
              "      <td>[0.2631, 0.28600000000000003, 0.0964, 0.1574, ...</td>\n",
              "      <td>[0.1501, 0.275, 0.0947, 0.18660000000000002, 0...</td>\n",
              "      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n",
              "      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n",
              "      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n",
              "      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n",
              "      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n",
              "      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_0049f53ba</td>\n",
              "      <td>GGAAAAAGCGCGCGCGGUUAGCGCGCGCUUUUGCGCGCGCUGUACC...</td>\n",
              "      <td>.....(((((((((((((((((((((((....)))))))))).)))...</td>\n",
              "      <td>EEEEESSSSSSSSSSSSSSSSSSSSSSSHHHHSSSSSSSSSSBSSS...</td>\n",
              "      <td>0.193</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[2.8272, 2.8272, 2.8272, 4.7343, 2.5676, 2.567...</td>\n",
              "      <td>[73705.3985, 73705.3985, 73705.3985, 73705.398...</td>\n",
              "      <td>[10.1986, 9.2418, 5.0933, 5.0933, 5.0933, 5.09...</td>\n",
              "      <td>[16.6174, 13.868, 8.1968, 8.1968, 8.1968, 8.19...</td>\n",
              "      <td>[15.4857, 7.9596, 13.3957, 5.8777, 5.8777, 5.8...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 2.2965, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[4.947, 4.4523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[4.8511, 4.0426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_006f36f57</td>\n",
              "      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n",
              "      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n",
              "      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n",
              "      <td>8.800</td>\n",
              "      <td>1</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n",
              "      <td>[0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...</td>\n",
              "      <td>[0.17020000000000002, 0.178, 0.111, 0.091, 0.0...</td>\n",
              "      <td>[0.1033, 0.1464, 0.1126, 0.09620000000000001, ...</td>\n",
              "      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n",
              "      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n",
              "      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n",
              "      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n",
              "      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n",
              "      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0082d463b</td>\n",
              "      <td>GGAAAAGCGCGCGCGCGCGCGCGAAAAAGCGCGCGCGCGCGCGCGC...</td>\n",
              "      <td>......((((((((((((((((......))))))))))))))))((...</td>\n",
              "      <td>EEEEEESSSSSSSSSSSSSSSSHHHHHHSSSSSSSSSSSSSSSSSS...</td>\n",
              "      <td>0.104</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[3.5229, 6.0748, 3.0374, 3.0374, 3.0374, 3.037...</td>\n",
              "      <td>[73705.3985, 73705.3985, 73705.3985, 73705.398...</td>\n",
              "      <td>[11.8007, 12.7566, 5.7733, 5.7733, 5.7733, 5.7...</td>\n",
              "      <td>[121286.7181, 121286.7182, 121286.7181, 121286...</td>\n",
              "      <td>[15.3995, 8.1124, 7.7824, 7.7824, 7.7824, 7.78...</td>\n",
              "      <td>[0.0, 2.2399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
              "      <td>[0.0, -0.5083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>[3.4248, 6.8128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[0.0, -0.8365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>[7.6692, -1.3223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_0087940f4</td>\n",
              "      <td>GGAAAAUAUAUAAUAUAUUAUAUAAAUAUAUUAUAGAAGUAUAAUA...</td>\n",
              "      <td>.....(((((((.((((((((((((.(((((((((....)))))))...</td>\n",
              "      <td>EEEEESSSSSSSBSSSSSSSSSSSSBSSSSSSSSSHHHHSSSSSSS...</td>\n",
              "      <td>0.423</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[1.665, 2.1728, 2.0041, 1.2405, 0.620200000000...</td>\n",
              "      <td>[4.2139, 3.9637000000000002, 3.2467, 2.4716, 1...</td>\n",
              "      <td>[3.0942, 3.015, 2.1212, 2.0552, 0.881500000000...</td>\n",
              "      <td>[2.6717, 2.4818, 1.9919, 2.5484999999999998, 1...</td>\n",
              "      <td>[1.3285, 3.6173, 1.3057, 1.3021, 1.1507, 1.150...</td>\n",
              "      <td>[0.8267, 2.6577, 2.8481, 0.40090000000000003, ...</td>\n",
              "      <td>[2.1058, 3.138, 2.5437000000000003, 1.0932, 0....</td>\n",
              "      <td>[4.7366, 4.6243, 1.2068, 1.1538, 0.0, 0.0, 0.7...</td>\n",
              "      <td>[2.2052, 1.7947000000000002, 0.7457, 3.1233, 0...</td>\n",
              "      <td>[0.0, 5.1198, -0.3551, -0.3518, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...                                            deg_50C\n",
              "index                ...                                                   \n",
              "0      id_001f94081  ...  [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...\n",
              "1      id_0049f53ba  ...  [7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "2      id_006f36f57  ...  [0.9501000000000001, 1.7974999999999999, 1.499...\n",
              "3      id_0082d463b  ...  [7.6692, -1.3223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "4      id_0087940f4  ...  [0.0, 5.1198, -0.3551, -0.3518, 0.0, 0.0, 0.0,...\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsiUXDsHpxqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d82fb99-c9ed-4f31-b286-4e71ed2d4787"
      },
      "source": [
        "print(full_train.columns)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'sequence', 'structure', 'predicted_loop_type', 'signal_to_noise',\n",
            "       'SN_filter', 'seq_length', 'seq_scored', 'reactivity_error',\n",
            "       'deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C',\n",
            "       'deg_error_50C', 'reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C',\n",
            "       'deg_50C'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iU5YK_-ZjZX"
      },
      "source": [
        "### Load the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6A548tNCC-_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "faec5f55-8a45-4b73-9593-28d9b510a707"
      },
      "source": [
        "# full_test = pd.read_json('/content/drive/MyDrive/1 MIDS/W207 Applied Machine Learning/Final Project/test.json', lines=True)\n",
        "full_test = pd.read_json('/content/drive/MyDrive/Final Project/test.json', lines=True)\n",
        "full_test = full_test.set_index(keys='index')\n",
        "full_test.info()\n",
        "full_test.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3634 entries, 0 to 3633\n",
            "Data columns (total 6 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   id                   3634 non-null   object\n",
            " 1   sequence             3634 non-null   object\n",
            " 2   structure            3634 non-null   object\n",
            " 3   predicted_loop_type  3634 non-null   object\n",
            " 4   seq_length           3634 non-null   int64 \n",
            " 5   seq_scored           3634 non-null   int64 \n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 198.7+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sequence</th>\n",
              "      <th>structure</th>\n",
              "      <th>predicted_loop_type</th>\n",
              "      <th>seq_length</th>\n",
              "      <th>seq_scored</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_00073f8be</td>\n",
              "      <td>GGAAAAGUACGACUUGAGUACGGAAAACGUACCAACUCGAUUAAAA...</td>\n",
              "      <td>......((((((((((.(((((.....))))))))((((((((......</td>\n",
              "      <td>EEEEEESSSSSSSSSSBSSSSSHHHHHSSSSSSSSSSSSSSSSHHH...</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000ae4237</td>\n",
              "      <td>GGAAACGGGUUCCGCGGAUUGCUGCUAAUAAGAGUAAUCUCUAAAU...</td>\n",
              "      <td>.....((((..((((((...(((((.....((((....)))).......</td>\n",
              "      <td>EEEEESSSSIISSSSSSIIISSSSSIIIIISSSSHHHHSSSSIIII...</td>\n",
              "      <td>130</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_00131c573</td>\n",
              "      <td>GGAAAACAAAACGGCCUGGAAGACGAAGGAAUUCGGCGCGAAGGCC...</td>\n",
              "      <td>...........((.(((.(.(..((..((..((((...))))..))...</td>\n",
              "      <td>EEEEEEEEEEESSISSSISISIISSIISSIISSSSHHHSSSSIISS...</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_00181fd34</td>\n",
              "      <td>GGAAAGGAUCUCUAUCGAAGGAUAGAGAUCGCUCGCGACGGCACGA...</td>\n",
              "      <td>......((((((((((....))))))))))((((((..((.(((.....</td>\n",
              "      <td>EEEEEESSSSSSSSSSHHHHSSSSSSSSSSSSSSSSIISSISSSHH...</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_0020473f7</td>\n",
              "      <td>GGAAACCCGCCCGCGCCCGCCCGCGCUGCUGCCGUGCCUCCUCUCC...</td>\n",
              "      <td>.....(((((((((((((((((((((((((((((((((((((((((...</td>\n",
              "      <td>EEEEESSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS...</td>\n",
              "      <td>130</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... seq_scored\n",
              "index                ...           \n",
              "0      id_00073f8be  ...         68\n",
              "1      id_000ae4237  ...         91\n",
              "2      id_00131c573  ...         68\n",
              "3      id_00181fd34  ...         68\n",
              "4      id_0020473f7  ...         91\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MQ-V55TFRt2"
      },
      "source": [
        "### Load BPPS files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jqR82sTFLXQ"
      },
      "source": [
        "# full_train = pd.read_json('/content/drive/MyDrive/1 MIDS/W207 Applied Machine Learning/Final Project/train.json', lines=True)\n",
        "# take average of base pair probability at each position \n",
        "\n",
        "def bpps_avg(df):\n",
        "  bpps_arr = []\n",
        "  for seq_id in df.id.to_list():\n",
        "    bpps_arr.append(np.load(f'/content/drive/MyDrive/Final Project/bpps/{seq_id}.npy').mean(axis=1))\n",
        "  return bpps_arr"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q_Nhff0rhy7"
      },
      "source": [
        "# add bpps data to the full train / test\n",
        "full_train[\"bpps_average\"] = bpps_avg(full_train)\n",
        "full_test[\"bpps_average\"] = bpps_avg(full_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "tSeVn7njvjVN",
        "outputId": "1eb784a4-9d14-4db9-fc3c-07f33f116b45"
      },
      "source": [
        "full_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sequence</th>\n",
              "      <th>structure</th>\n",
              "      <th>predicted_loop_type</th>\n",
              "      <th>signal_to_noise</th>\n",
              "      <th>SN_filter</th>\n",
              "      <th>seq_length</th>\n",
              "      <th>seq_scored</th>\n",
              "      <th>reactivity_error</th>\n",
              "      <th>deg_error_Mg_pH10</th>\n",
              "      <th>deg_error_pH10</th>\n",
              "      <th>deg_error_Mg_50C</th>\n",
              "      <th>deg_error_50C</th>\n",
              "      <th>reactivity</th>\n",
              "      <th>deg_Mg_pH10</th>\n",
              "      <th>deg_pH10</th>\n",
              "      <th>deg_Mg_50C</th>\n",
              "      <th>deg_50C</th>\n",
              "      <th>bpps_average</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_001f94081</td>\n",
              "      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n",
              "      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n",
              "      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n",
              "      <td>6.894</td>\n",
              "      <td>1</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n",
              "      <td>[0.26130000000000003, 0.38420000000000004, 0.1...</td>\n",
              "      <td>[0.2631, 0.28600000000000003, 0.0964, 0.1574, ...</td>\n",
              "      <td>[0.1501, 0.275, 0.0947, 0.18660000000000002, 0...</td>\n",
              "      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n",
              "      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n",
              "      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n",
              "      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n",
              "      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n",
              "      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n",
              "      <td>[0.0018555354205607479, 0.001716936448598131, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_0049f53ba</td>\n",
              "      <td>GGAAAAAGCGCGCGCGGUUAGCGCGCGCUUUUGCGCGCGCUGUACC...</td>\n",
              "      <td>.....(((((((((((((((((((((((....)))))))))).)))...</td>\n",
              "      <td>EEEEESSSSSSSSSSSSSSSSSSSSSSSHHHHSSSSSSSSSSBSSS...</td>\n",
              "      <td>0.193</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[2.8272, 2.8272, 2.8272, 4.7343, 2.5676, 2.567...</td>\n",
              "      <td>[73705.3985, 73705.3985, 73705.3985, 73705.398...</td>\n",
              "      <td>[10.1986, 9.2418, 5.0933, 5.0933, 5.0933, 5.09...</td>\n",
              "      <td>[16.6174, 13.868, 8.1968, 8.1968, 8.1968, 8.19...</td>\n",
              "      <td>[15.4857, 7.9596, 13.3957, 5.8777, 5.8777, 5.8...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 2.2965, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[4.947, 4.4523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[4.8511, 4.0426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "      <td>[0.0015779091218742912, 0.0009977514074258377,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_006f36f57</td>\n",
              "      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n",
              "      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n",
              "      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n",
              "      <td>8.800</td>\n",
              "      <td>1</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n",
              "      <td>[0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...</td>\n",
              "      <td>[0.17020000000000002, 0.178, 0.111, 0.091, 0.0...</td>\n",
              "      <td>[0.1033, 0.1464, 0.1126, 0.09620000000000001, ...</td>\n",
              "      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n",
              "      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n",
              "      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n",
              "      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n",
              "      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n",
              "      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n",
              "      <td>[0.0006243667443574299, 0.0004143690368910073,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0082d463b</td>\n",
              "      <td>GGAAAAGCGCGCGCGCGCGCGCGAAAAAGCGCGCGCGCGCGCGCGC...</td>\n",
              "      <td>......((((((((((((((((......))))))))))))))))((...</td>\n",
              "      <td>EEEEEESSSSSSSSSSSSSSSSHHHHHHSSSSSSSSSSSSSSSSSS...</td>\n",
              "      <td>0.104</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[3.5229, 6.0748, 3.0374, 3.0374, 3.0374, 3.037...</td>\n",
              "      <td>[73705.3985, 73705.3985, 73705.3985, 73705.398...</td>\n",
              "      <td>[11.8007, 12.7566, 5.7733, 5.7733, 5.7733, 5.7...</td>\n",
              "      <td>[121286.7181, 121286.7182, 121286.7181, 121286...</td>\n",
              "      <td>[15.3995, 8.1124, 7.7824, 7.7824, 7.7824, 7.78...</td>\n",
              "      <td>[0.0, 2.2399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
              "      <td>[0.0, -0.5083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>[3.4248, 6.8128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[0.0, -0.8365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>[7.6692, -1.3223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "      <td>[0.002121767476635514, 0.0017233071962616823, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_0087940f4</td>\n",
              "      <td>GGAAAAUAUAUAAUAUAUUAUAUAAAUAUAUUAUAGAAGUAUAAUA...</td>\n",
              "      <td>.....(((((((.((((((((((((.(((((((((....)))))))...</td>\n",
              "      <td>EEEEESSSSSSSBSSSSSSSSSSSSBSSSSSSSSSHHHHSSSSSSS...</td>\n",
              "      <td>0.423</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[1.665, 2.1728, 2.0041, 1.2405, 0.620200000000...</td>\n",
              "      <td>[4.2139, 3.9637000000000002, 3.2467, 2.4716, 1...</td>\n",
              "      <td>[3.0942, 3.015, 2.1212, 2.0552, 0.881500000000...</td>\n",
              "      <td>[2.6717, 2.4818, 1.9919, 2.5484999999999998, 1...</td>\n",
              "      <td>[1.3285, 3.6173, 1.3057, 1.3021, 1.1507, 1.150...</td>\n",
              "      <td>[0.8267, 2.6577, 2.8481, 0.40090000000000003, ...</td>\n",
              "      <td>[2.1058, 3.138, 2.5437000000000003, 1.0932, 0....</td>\n",
              "      <td>[4.7366, 4.6243, 1.2068, 1.1538, 0.0, 0.0, 0.7...</td>\n",
              "      <td>[2.2052, 1.7947000000000002, 0.7457, 3.1233, 0...</td>\n",
              "      <td>[0.0, 5.1198, -0.3551, -0.3518, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[0.00037720331356832457, 0.0007496862422422686...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...                                       bpps_average\n",
              "index                ...                                                   \n",
              "0      id_001f94081  ...  [0.0018555354205607479, 0.001716936448598131, ...\n",
              "1      id_0049f53ba  ...  [0.0015779091218742912, 0.0009977514074258377,...\n",
              "2      id_006f36f57  ...  [0.0006243667443574299, 0.0004143690368910073,...\n",
              "3      id_0082d463b  ...  [0.002121767476635514, 0.0017233071962616823, ...\n",
              "4      id_0087940f4  ...  [0.00037720331356832457, 0.0007496862422422686...\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E85R52RR7cgn"
      },
      "source": [
        "# export data set to csv to avoid reload bpps file, which takes 30 mins.\n",
        "# full_train.to_csv(\"/content/drive/MyDrive/Final Project/full_train_w_bpps.csv\")\n",
        "# full_test.to_csv(\"/content/drive/MyDrive/Final Project/full_test_w_bpps.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyYfBDlVCd1T"
      },
      "source": [
        "# #load the file with bpps from google drive\n",
        "# full_train_w_bpps = pd.read_csv(\"/content/drive/MyDrive/Final Project/full_train_w_bpps.csv\")\n",
        "# full_test_w_bpps = pd.read_csv(\"/content/drive/MyDrive/Final Project/full_test_w_bpps.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfYne_DdFP8u"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMhwZJBHZyCz"
      },
      "source": [
        "## Start EDA here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXeiNNbVEqCg"
      },
      "source": [
        "First, we start with sanity check. According to competition description, the test set is a mixture of 'private test' and 'public test' data, differ by the length of RNA sequence (seq_length). Here we separate the test set into two sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CFi_48DCHgW"
      },
      "source": [
        "public_test = full_test[full_test.seq_length==107].reset_index()\n",
        "private_test = full_test[full_test.seq_length==130].reset_index()\n",
        "print(public_test.shape)\n",
        "print(private_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqrgz8Ia2f0T"
      },
      "source": [
        "Checking the training data as with quick descrption.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhMqSceC4OrT"
      },
      "source": [
        "include =['object', 'float', 'int']\n",
        "descriptive_summary = full_train.describe(include = include)\n",
        "\n",
        "descriptive_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Eqv3tl-J4Q"
      },
      "source": [
        "The data is structured quite complicated with different length for sequences can be different in different data set, so just double check that length is expected. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6II4mYg8wz5"
      },
      "source": [
        "def check_seq_length (data,seq, expected_length):\n",
        "  return data.apply(lambda x:len(x[seq]) == x[expected_length], axis = 1)\n",
        "\n",
        "for seq in ['sequence', 'structure', 'predicted_loop_type']: \n",
        "  print(f'Is the length for {seq} as expected?', all(check_seq_length(full_train, seq, 'seq_length')))\n",
        "\n",
        "\n",
        "for seq in ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']: \n",
        "  print(f'Is the length for {seq} as expected?', all(check_seq_length(full_train, seq, 'seq_scored')))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sSeGOxvZ2DJ"
      },
      "source": [
        "# Function to plot correlation matricies\n",
        "def corrdot(*args, **kwargs):\n",
        "    corr_r = args[0].corr(args[1], 'pearson')\n",
        "    corr_text = f\"{corr_r:2.2f}\".replace(\"0.\", \".\")\n",
        "    ax = plt.gca()\n",
        "    ax.set_axis_off()\n",
        "    marker_size = abs(corr_r) * 10000\n",
        "    ax.scatter([.5], [.5], marker_size, [corr_r], alpha=0.6, cmap=\"coolwarm\",\n",
        "               vmin=-1, vmax=1, transform=ax.transAxes)\n",
        "    font_size = abs(corr_r) * 40 + 5\n",
        "    ax.annotate(corr_text, [.5, .5,],  xycoords=\"axes fraction\",\n",
        "                ha='center', va='center', fontsize=font_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju9gZ8BB2EHO"
      },
      "source": [
        "RNA contains four bases and form G-C and A-U paris. COVID-19 mRNA vaccine is single-stranded RNA and it forms pairs as it floats and folds itself. Among the two pair types, G-C pair tends to be more statble than A-U pair due to the bonding strength. Therefore, the higher weight of G and C bases in a RNA will make RNA less degradable. Furthermore, structure and loop type also affects RNA degradation. Unpaired bases are more vulnerable to temperature and UV challenges. Stem stucture tend to be more stable tham loops.\n",
        "Below, we are exploring the weight of each base in each RNA sequence, weight of possible pairings, and weight of different structure types. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzrKeeBfadcn"
      },
      "source": [
        "What is the fraction of each base in each observation? \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVmA-NV7aOUn"
      },
      "source": [
        "# Count the fraction of all the bases in the sequences\n",
        "bases = []\n",
        "\n",
        "for base in range(len(full_train)):\n",
        "    counts = dict(count(full_train.iloc[base]['sequence']))\n",
        "    bases.append((\n",
        "        counts['A'] / 107,\n",
        "        counts['G'] / 107,\n",
        "        counts['C'] / 107,\n",
        "        counts['U'] / 107\n",
        "    ))\n",
        "    \n",
        "bases = pd.DataFrame(bases, columns=['A_percent', 'G_percent', 'C_percent', 'U_percent'])\n",
        "bases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzUfV8NvAaUx"
      },
      "source": [
        "include =['object', 'float', 'int']\n",
        "base_summary = bases.describe(include = include)\n",
        "\n",
        "base_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80s78GrHAorR"
      },
      "source": [
        "Of the 4 bases, A has the highest average prevalence while U is the least prevalent on average."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6xBZmICbBzd"
      },
      "source": [
        "What is fraction of each base pair in each observation? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z7YbQ1SbF3J"
      },
      "source": [
        "pairs = []\n",
        "all_partners = []\n",
        "for base in range(len(full_train)):\n",
        "  partners = [-1 for symbol in range(130)]\n",
        "  pairs_dict = {('U', 'G'): 0, ('C', 'G'): 0, ('U', 'A'): 0, ('G', 'C'): 0, ('A', 'U'): 0, ('G', 'U'): 0}\n",
        "  queue = []\n",
        "  for symbol in range(0, len(full_train.iloc[base]['structure'])):\n",
        "    if full_train.iloc[base]['structure'][symbol] == '(':\n",
        "      queue.append(symbol)\n",
        "    if full_train.iloc[base]['structure'][symbol] == ')':\n",
        "      first = queue.pop()\n",
        "      pairs_dict[(full_train.iloc[base]['sequence'][first], full_train.iloc[base]['sequence'][symbol])] += 1\n",
        "      partners[first] = symbol\n",
        "      partners[symbol] = first\n",
        "  \n",
        "  all_partners.append(partners)\n",
        "  \n",
        "  pairs_num = 0\n",
        "  pairs_unique = [('U', 'G'), ('C', 'G'), ('U', 'A'), ('G', 'C'), ('A', 'U'), ('G', 'U')]\n",
        "  for item in pairs_dict:\n",
        "    pairs_num += pairs_dict[item]\n",
        "  add_tuple = list()\n",
        "  for item in pairs_unique:\n",
        "    add_tuple.append(pairs_dict[item]/pairs_num)\n",
        "  pairs.append(add_tuple)\n",
        "    \n",
        "pairs = pd.DataFrame(pairs, columns=['U-G', 'C-G', 'U-A', 'G-C', 'A-U', 'G-U'])\n",
        "full_train['partners'] = all_partners\n",
        "pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBTQIMptA7I6"
      },
      "source": [
        "include =['object', 'float', 'int']\n",
        "pair_summary = pairs.describe(include = include)\n",
        "\n",
        "pair_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr_MrH85BeUt"
      },
      "source": [
        "Looking at the base pairs, on average, the G-C pair is the most prevalent while the U-G pair is the least"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbQ8lhElceHy"
      },
      "source": [
        "What are the total counts of base pairs in the whole training set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY3uLy-RcccQ"
      },
      "source": [
        "pairs_dict = {('U', 'G'): 0, ('C', 'G'): 0, ('U', 'A'): 0, ('G', 'C'): 0, ('A', 'U'): 0, ('G', 'U'): 0}\n",
        "queue = []\n",
        "for base in range(len(full_train)):\n",
        "  observation = full_train.iloc[base]\n",
        "  for symbol in range(len(observation['structure'])):\n",
        "    if observation['structure'][symbol] == '(':\n",
        "      queue.append(symbol)\n",
        "    if observation['structure'][symbol] == ')':\n",
        "      first = queue.pop()\n",
        "      pairs_dict[(observation['sequence'][first], observation['sequence'][symbol])] += 1\n",
        "\n",
        "                \n",
        "pairs_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N34sYeLLckFI"
      },
      "source": [
        "names = []\n",
        "values = []\n",
        "for item in pairs_dict:\n",
        "    names.append(item)\n",
        "    values.append(pairs_dict[item])\n",
        "    \n",
        "df = pd.DataFrame()\n",
        "df['pair'] = names\n",
        "df['count'] = values\n",
        "df['pair'] = df['pair'].astype(str)\n",
        "\n",
        "fig = px.bar(\n",
        "    df, \n",
        "    x='pair', \n",
        "    y=\"count\", \n",
        "    orientation='v', \n",
        "    title='Pair types', \n",
        "    height=400, \n",
        "    width=800\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DdTNwiacq1W"
      },
      "source": [
        "In the predicted loop type column, the following symbols were used to represent\n",
        "base pair categories.\n",
        "\n",
        "S: paired \"Stem\"\n",
        "\n",
        "M: Multiloop\n",
        "\n",
        "I: Internal loop \n",
        "\n",
        "B: Bulge\n",
        "\n",
        "H: Hairpin loop \n",
        "\n",
        "E: dangling End \n",
        "\n",
        "X: eXternal loop \n",
        "\n",
        "What is the fraction of each category in each observation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beRFtkzxcp8l"
      },
      "source": [
        "loops = []\n",
        "for prediction in range(len(full_train)):\n",
        "    counts = dict(count(full_train.iloc[prediction]['predicted_loop_type']))\n",
        "    types = ['E', 'S', 'H', 'B', 'X', 'I', 'M']\n",
        "    row = []\n",
        "    for item in types:\n",
        "      if item in counts:\n",
        "        row.append(counts[item] / 107)\n",
        "      else:\n",
        "        row.append(0)\n",
        "    loops.append(row)\n",
        "    \n",
        "loops = pd.DataFrame(loops, columns=types)\n",
        "loops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDgqUUgqFeKI"
      },
      "source": [
        "Looking at the loop type summaries, on average, S is the most prevalent type at 44.21% and B is the least present at 1.12%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZZ-h0exFdXG"
      },
      "source": [
        "include =['object', 'float', 'int']\n",
        "loops_summary = loops.describe(include = include)\n",
        "\n",
        "loops_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raaG8q0gdQcl"
      },
      "source": [
        "res_dict = {'E':0, 'S':0, 'H':0, 'B':0, 'X':0, 'I':0, 'M':0}\n",
        "for prediction in range(len(full_train)):\n",
        "    observation = full_train.iloc[prediction]\n",
        "    pred_symbol = dict(count(observation['predicted_loop_type']))\n",
        "    for item in pred_symbol:\n",
        "      if item in pred_symbol:\n",
        "        res_dict[item] += pred_symbol[item]\n",
        "\n",
        "res_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnOmrdpidT4N"
      },
      "source": [
        "names = []\n",
        "values = []\n",
        "for item in res_dict:\n",
        "    names.append(item)\n",
        "    values.append(res_dict[item])\n",
        "    \n",
        "df = pd.DataFrame()\n",
        "df['loop_type'] = names\n",
        "df['count'] = values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbkr8rpPdWH8"
      },
      "source": [
        "fig = px.bar(\n",
        "    df, \n",
        "    x='loop_type', \n",
        "    y=\"count\", \n",
        "    orientation='v', \n",
        "    title='Predicted loop types', \n",
        "    height=400, \n",
        "    width=600\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-SwQGyrdZII"
      },
      "source": [
        "#pairs and loops\n",
        "pairs.reset_index(drop=True, inplace=True)\n",
        "loops.reset_index(drop=True, inplace=True)\n",
        "\n",
        "correlation_frame = pd.concat([pairs, loops], axis=1)\n",
        "correlation_frame\n",
        "\n",
        "g = sns.PairGrid(correlation_frame, aspect=1.4, diag_sharey=False)\n",
        "g.map_lower(sns.regplot, lowess=True, ci=False, line_kws={'color': 'black'})\n",
        "g.map_diag(sns.histplot, kde_kws={'color': 'black'})\n",
        "g.map_upper(corrdot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFGcxNx0GJ1E"
      },
      "source": [
        "Looking at correlations between base pairs and loop types, we see a high correlation of -.82 between loop types E and S. It looks like there may be an strong grouping of data anchoring this relationship. There is also a strong inverse relationship of -.60 between U-A and G-C pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kM1r3HigY7C"
      },
      "source": [
        "Signal to noise ratio exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzxK4pq7gcF-"
      },
      "source": [
        "fig = px.histogram(\n",
        "    full_train, \n",
        "    \"signal_to_noise\", \n",
        "    nbins=25, \n",
        "    title='signal_to_noise histogram', \n",
        "    width=700,\n",
        "    height=500\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfx2dWjQgyf0"
      },
      "source": [
        "ds = full_train['SN_filter'].value_counts().reset_index()\n",
        "ds.columns = ['SN_filter', 'count']\n",
        "fig = px.pie(\n",
        "    ds, \n",
        "    values='count', \n",
        "    names=\"SN_filter\", \n",
        "    title='SN_filter pie chart', \n",
        "    width=500, \n",
        "    height=500\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT-i2ElbDUQd"
      },
      "source": [
        "Looking for correlation in the means of the prediction targets showed us correlation among the observations/samples. For example, observations with a higher mean deg_50_Mg_50C had a higher meand deg_ph10. This relationship should be further explored at the individual base level. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM2_grtyCbWH"
      },
      "source": [
        "full_train['mean_reactivity'] = full_train['reactivity'].apply(lambda x: np.mean(x))\n",
        "full_train['mean_deg_Mg_pH10'] = full_train['deg_Mg_pH10'].apply(lambda x: np.mean(x))\n",
        "full_train['mean_deg_Mg_50C'] = full_train['deg_Mg_50C'].apply(lambda x: np.mean(x))\n",
        "full_train['mean_deg_pH10'] = full_train['deg_pH10'].apply(lambda x: np.mean(x))\n",
        "full_train['mean_deg_50C'] = full_train['deg_50C'].apply(lambda x: np.mean(x))\n",
        "\n",
        "full_train_plots = full_train.iloc[:,19:25]\n",
        "\n",
        "full_train_plots\n",
        "\n",
        "sns.set(style='white', font_scale=1)\n",
        "g = sns.PairGrid(full_train_plots, aspect=1.4, diag_sharey=False)\n",
        "g.map_lower(sns.regplot, lowess=True, ci=False, line_kws={'color': 'black'})\n",
        "g.map_diag(sns.histplot, kde_kws={'color': 'black'})\n",
        "g.map_upper(corrdot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM9Sp2yGZrG0"
      },
      "source": [
        "## Start modeling here\n",
        "\n",
        "### Feature creation\n",
        "\n",
        "In this problem, our initial input variables are RNA sequence, structure, and loop types, which are represented by characters. The models can not directly consuming those features and we will need to convert them into a numerical format.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57_a6AI-_Ifs"
      },
      "source": [
        "\n",
        "# Create an dictionary to map character to a integer\n",
        "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
        "\n",
        "def tokenise(data, dic):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to convert sequence, structure and predited_loop_type into one long numerical \n",
        "  feature array for each RNA sample \n",
        "  \"\"\"\n",
        "\n",
        "  # grab the data \n",
        "  temp = list(data.sequence) + list(data.structure) + list(data.predicted_loop_type)\n",
        "  temp = np.array(temp)\n",
        "\n",
        "  # creating mapping array \n",
        "  k = np.array(list(dic.keys()))\n",
        "  v = np.array(list(dic.values()))\n",
        "\n",
        "  # Get argsort indices\n",
        "  sidx = k.argsort()\n",
        "\n",
        "  # map the initial array to integers \n",
        "  ks = k[sidx]\n",
        "  vs = v[sidx]\n",
        "  return vs[np.searchsorted(ks,temp)]\n",
        "\n",
        "# apply the function to train and test data \n",
        "full_train['feature_array'] = full_train.apply(lambda x: tokenise(x, token2int), axis = 1)\n",
        "public_test['feature_array'] =public_test.apply(lambda x: tokenise(x, token2int), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSEhm6a0o6PQ"
      },
      "source": [
        "# Checking if the shape is as expected \n",
        "np.array(full_train['feature_array'].tolist()).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu9RiZtzo7MT"
      },
      "source": [
        " # split into a training, a dev and and a test data\n",
        "train_data, dev_test = train_test_split(\n",
        "    full_train, test_size=.2, random_state=34)\n",
        " \n",
        "dev_data, test_data = train_test_split(\n",
        "    dev_test, test_size=.5, random_state=34)\n",
        "\n",
        "dev_data.shape \n",
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaSLc2e-B9Xi"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiOAMfnBDgNo"
      },
      "source": [
        "# import warnings\n",
        "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "\n",
        "# train_feature = np.array(train_data['feature_array'].tolist())\n",
        "# train_reactivity = np.array(train_data['reactivity'].tolist())\n",
        "\n",
        "# dev_feature = np.array(dev_data['feature_array'].tolist())\n",
        "# dev_reactivity = np.array(dev_data['reactivity'].tolist())\n",
        "\n",
        "\n",
        "# clf_single = MLPRegressor()\n",
        "# clf_single.fit(train_feature, train_reactivity)\n",
        "# print(f'Initial model accuracy {clf_single.score(dev_feature, dev_reactivity)}')\n",
        "\n",
        "\n",
        "# # def a grid search for var_smoothing \n",
        "# params = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0],\n",
        "#           'hidden_layer_sizes': [(100,), (200,), (100, 100), (100, 50, 50, 50)]\n",
        "#           }\n",
        "\n",
        "# # start a grid search with min train data \n",
        "# clf = GridSearchCV(clf_single, params, cv=5)\n",
        "# clf.fit(train_feature, train_reactivity)\n",
        "\n",
        "# # get the best performing model from grid search \n",
        "# clf_best = clf.best_estimator_\n",
        "# clf_best.fit(train_feature, train_reactivity)\n",
        "# print(f'Final model accuracy {clf_best.score(dev_feature, dev_reactivity)}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQErkFOVkAYk"
      },
      "source": [
        "We are choosing to start with neural network due to the complexity of the problem. The input features are just tokenised biological representation, they are not strictly numerical nor categorical. So we think a neural network should be able to handle the complexity inside the problem. General field research and browsing through past submission also proven the choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVR7E8hInVw0"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "def build_nn(input_feature, output_target, params,  dev_feature, dev_target):\n",
        "  \"\"\"\n",
        "  Training function to conduct grid search for nerual net works \n",
        "  \"\"\"    \n",
        "\n",
        "  # initiate a single ANN\n",
        "  clf_single = MLPRegressor(max_iter=300, learning_rate = 'adaptive')\n",
        "  # clf_single.fit(input_feature, output_target)\n",
        "  # print(f'Initial model accuracy {clf_single.score(dev_feature, dev_reactivity)}')\n",
        "\n",
        "  # def a grid search for var_smoothing \n",
        "\n",
        "  # start a grid search with 5 fold CV\n",
        "  clf = GridSearchCV(clf_single, params, cv=5, \n",
        "                     n_jobs = 2,\n",
        "                     scoring = 'neg_root_mean_squared_error')\n",
        "  clf.fit(input_feature, output_target)\n",
        "\n",
        "  # get the best performing model from grid search \n",
        "  clf_best = clf.best_estimator_\n",
        "  clf_best.fit(input_feature, output_target)\n",
        "  \n",
        "  return clf_best"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYqzvqf8KQz9"
      },
      "source": [
        "# start grid search for all desired outputs\n",
        "targets = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
        "nn_estimator = [] \n",
        "predictions = []\n",
        "scores = []\n",
        "        \n",
        "#def a set of params to use for grid search \n",
        "params = {'alpha': [ 0.0001, 0.001, 0.01, 0.1, 1.0, 2.0, 10.0],\n",
        "          'hidden_layer_sizes': [(100,), (200,), (100, 100), (100, 50, 50, 50)]\n",
        "          }\n",
        "\n",
        "# prep feature \n",
        "train_feature = np.array(train_data['feature_array'].tolist())\n",
        "dev_feature = np.array(dev_data['feature_array'].tolist())\n",
        "test_feature = np.array(test_data['feature_array'].tolist())\n",
        "\n",
        "\n",
        "for target in targets: \n",
        "  # prep the data\n",
        "  output_target = np.array(train_data[target].tolist())\n",
        "  dev_target = np.array(dev_data[target].tolist())\n",
        "  test_target = np.array(test_data[target].tolist())\n",
        "\n",
        "\n",
        "  # start grid search\n",
        "  best_model = build_nn(train_feature, output_target, params,  dev_feature, dev_target)\n",
        "  # save the best model\n",
        "  nn_estimator +=[best_model]\n",
        "  # and include prediction\n",
        "  target_predict = best_model.predict(test_feature)\n",
        "  predictions.append(list(target_predict))\n",
        "\n",
        "  score = np.sqrt(metrics.mean_squared_error(test_target, target_predict))\n",
        "  scores.append([score])\n",
        "  print(f'Final model for {target} has RMSE: {score}')\n",
        "\n",
        "\n",
        "# It takes really long time to do the gridsearch, so make some noise when it finish\n",
        "import IPython\n",
        "display(IPython.display.Audio(url=\"https://www.soundhelix.com/examples/mp3/SoundHelix-Song-14.mp3\", autoplay=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqIoOorzDdBc"
      },
      "source": [
        "for target, estimator in zip(targets, nn_estimator):\n",
        "  print(f'the baseline model for {target} is a {estimator.n_layers_}-layer neural network with alpha {estimator.get_params()[\"alpha\"]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNulMgKZBstG"
      },
      "source": [
        "### Baseline score\n",
        "\n",
        "We use the same metric as the competition is using to evaluate the score, a column wise root mean square error. We have used RMSE previously when selecting models from grid search, so just taking average across the column. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FubLOBXUV-Ja"
      },
      "source": [
        "print(f'The baseline model score is {np.average(scores)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le21-gUB7XYW"
      },
      "source": [
        "### Showing the prediction result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEQRY2Kr4NDR"
      },
      "source": [
        "result = pd.DataFrame(dict(zip(targets, predictions)), index=test_data.id)\n",
        "result.to_csv('/content/drive/MyDrive/1 MIDS/W207 Applied Machine Learning/Final Project/base_line_result.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27bHsIjjEkAK"
      },
      "source": [
        "## Some thoughts on next steps\n",
        "1. the best performing models in the competition submissions are variants of LSTM, which makes sense as we always want to previous bases in a sequence would matter, should we should take a look\n",
        "2. the bpps data is worthy exprimenting.\n",
        "3. the sequence been scored is a shorter set compared to sequence provieded, maybe we can throw away the bottom part to reduce the dimension.\n",
        "4. more feature engineering, using the base pairs for e.g.\n",
        "    - explore relationship of base pairs with prediction targets in more granular detail. For example are G bases associated with higher reactivity?\n",
        "5. Use the competition specific scoring metric to evaluate performance.\n",
        "6. We used seperate models for 5 output variables, since each output is already non-scalar, we can also try to predict all 5 output with one model.\n",
        "7. The ANN are suffering from covergence warmings despite a large epoches. We could try other optimisation methods. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11OI9iJ4GAY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQDrKA1w4If_"
      },
      "source": [
        "### Recurrent NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-BKcbnF8Yaq"
      },
      "source": [
        "# Tokenize structure, loop type to separate columns\n",
        "\n",
        "# Create an dictionary to map character to a integer\n",
        "token2int = {x:i for i, x in enumerate('().BEHIMSX')}  # only the predicted_loop_type and strucutre \n",
        "\n",
        "def tokenise_structure(data, dic):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to convert (sequence,) structure and predited_loop_type into one long numerical \n",
        "  feature array for each RNA sample \n",
        "  \"\"\"\n",
        "\n",
        "  # grab the data; remove the sequence\n",
        "  temp = list(data.structure) \n",
        "  temp = np.array(temp)\n",
        "\n",
        "  # creating mapping array \n",
        "  k = np.array(list(dic.keys()))   # index array\n",
        "  v = np.array(list(dic.values()))   # value array\n",
        "\n",
        "  # Get argsort indices\n",
        "  sidx = k.argsort()\n",
        "\n",
        "  # map the initial array to integers \n",
        "  ks = k[sidx]\n",
        "  vs = v[sidx]\n",
        "  return vs[np.searchsorted(ks,temp)]\n",
        "\n",
        "def tokenise_loop_type(data, dic):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to convert (sequence,) structure and predited_loop_type into one long numerical \n",
        "  feature array for each RNA sample \n",
        "  \"\"\"\n",
        "\n",
        "  # grab the data; remove the sequence\n",
        "  temp = list(data.predicted_loop_type) \n",
        "  temp = np.array(temp)\n",
        "\n",
        "  # creating mapping array \n",
        "  k = np.array(list(dic.keys()))   # index array\n",
        "  v = np.array(list(dic.values()))   # value array\n",
        "\n",
        "  # Get argsort indices\n",
        "  sidx = k.argsort()\n",
        "\n",
        "  # map the initial array to integers \n",
        "  ks = k[sidx]\n",
        "  vs = v[sidx]\n",
        "  return vs[np.searchsorted(ks,temp)]\n",
        "\n",
        "# apply the function to train and test data \n",
        "full_train['token_structure'] = full_train.apply(lambda x: tokenise_structure(x, token2int), axis = 1)\n",
        "full_train['token_looptype'] = full_train.apply(lambda x: tokenise_loop_type(x, token2int), axis = 1)\n",
        "full_test['token_structure'] = full_test.apply(lambda x: tokenise_structure(x, token2int), axis = 1)\n",
        "full_test['token_looptype'] = full_test.apply(lambda x: tokenise_loop_type(x, token2int), axis = 1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqF_LEKqvy9W",
        "outputId": "5196340e-bd21-4bf6-caf3-97d8aa9c1570"
      },
      "source": [
        "# split train, dev, test set \n",
        "train_data, dev_test = train_test_split(\n",
        "    full_train, test_size=.2, random_state=34)\n",
        " \n",
        "dev_data, test_data = train_test_split(\n",
        "    dev_test, test_size=.5, random_state=34)\n",
        "\n",
        "print(dev_data.shape)\n",
        "print(train_data.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(240, 21)\n",
            "(1920, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyoVXPVz4L2C"
      },
      "source": [
        "# features put into models\n",
        "features = [\"token_structure\", \"token_looptype\", \"bpps_average\"]\n",
        "label = \"reactivity\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QRAqVmjMq1M"
      },
      "source": [
        "# prepare train/dev data (x)\n",
        "# for each sample, pair features of interest into each position\n",
        "def pair_features(data, features):\n",
        "  output_df = pd.DataFrame()\n",
        "  output_df[\"id\"] = data[\"id\"]\n",
        "\n",
        "  # type the columns to list, only use first 68 positions\n",
        "  for feature in features:\n",
        "    output_df[feature] = data[feature].apply(lambda x: list(x)[:68])\n",
        "  # explode to each position of each sample\n",
        "  output_df = output_df.set_index(['id']).apply(pd.Series.explode).reset_index()\n",
        "  # new feature at each position= [\"token_structure\", \"token_looptype\", \"bpps_average\"]\n",
        "  output_df[\"feature_paird\"] = output_df[features].values.tolist()\n",
        "  # group by samples\n",
        "  output = output_df.groupby(\"id\")[\"feature_paird\"].apply(list).reset_index(name='paird_feature')\n",
        "  return output"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQh8bjDnwdJ8"
      },
      "source": [
        "# generate train and dev data. \n",
        "x_train_df = pair_features(train_data, features)\n",
        "x_dev_df = pair_features(dev_data, features)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r57lnWTRh9eU"
      },
      "source": [
        "# convert to tf object\n",
        "x_train = tf.convert_to_tensor(x_train_df['paird_feature'].tolist())\n",
        "x_dev = tf.convert_to_tensor(x_dev_df['paird_feature'].tolist())"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqN1HBo4wmB-"
      },
      "source": [
        "# prepare train/dev label (y)\n",
        "y_train = tf.convert_to_tensor(train_data[label].tolist())\n",
        "y_dev = tf.convert_to_tensor(dev_data[label].tolist())"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0BiHw5RjYj8",
        "outputId": "b6155e39-7fa1-4c1c-cac8-f74cf4cf9f80"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([-0.13, 2.419, 0.8159000000000001, 0.2684, 0.265, 0.1333, 0.2584, 0.0, 0.0, 0.25520000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2521, 0.0, 0.0, 0.49210000000000004, 0.4807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4697, 0.23220000000000002, 0.45430000000000004, 2.0464, 0.0, 0.40130000000000005, 0.19870000000000002, 0.0, 0.0, 0.1968, 0.0, 0.0, 0.7585000000000001, 1.7368999999999999, 2.0356, 0.4803, 1.1636, 0.5512, 0.272, 0.1351, 0.1342, 0.265, 0.39, 0.25680000000000003, 0.12760000000000002, 0.2521, 0.249, 0.0, 0.0, 0.0, 0.12380000000000001, 0.123, 0.0, 0.0, 0.2432, 0.12090000000000001, 0.0, 0.0, 0.1202, 0.2207, 0.45930000000000004]),\n",
              "       list([0.4892, 1.7883, 1.287, 0.9163, 0.6269, 0.7779, 0.17500000000000002, 0.2685, 0.1718, 0.47840000000000005, 0.8631000000000001, 0.5048, 1.2021, 0.9567, 1.2217, 0.7601, 0.3129, 0.34690000000000004, 0.22560000000000002, 0.4797, 0.5155000000000001, 0.2679, 0.133, 0.2614, 0.11960000000000001, 0.0637, 0.3765, 0.5775, 0.8066, 0.6525000000000001, 0.39540000000000003, 0.0862, 0.0354, 0.3398, 0.582, 0.0907, 0.0456, 0.2822, 0.2937, 0.9667, 0.686, 0.2652, 0.6940000000000001, 0.4753, 1.0238, 0.0907, 0.0449, 0.2511, 0.33790000000000003, 0.4571, 0.8369000000000001, 0.5607, 0.5792, 0.0718, 0.1403, 0.512, 0.0897, 0.0422, 0.1642, 0.30560000000000004, 0.3471, 0.4344, 0.4771, 0.8866, 0.5146000000000001, 0.64, 0.7314, 0.45630000000000004]),\n",
              "       list([0.4706, 1.5268000000000002, 0.9766, 0.8245, 1.1605, 0.5788, 0.613, 0.4561, 0.16240000000000002, 0.1355, 0.24330000000000002, 0.0489, -0.0177, 0.3089, 0.5993, 0.1414, 0.0407, 0.7491, 0.8979, 0.6234000000000001, 0.518, 0.5374, 0.3024, 0.9982000000000001, 0.33290000000000003, 0.2738, 0.12240000000000001, 0.19790000000000002, 0.8255, 1.1421999999999999, 0.6042000000000001, 0.6217, 0.38130000000000003, 0.1622, 0.25670000000000004, 0.1618, 0.1144, 0.2082, 0.0666, 0.23620000000000002, 0.0942, 0.0443, 0.0988, 0.4131, 0.554, 0.6219, 0.3075, 0.4837, 0.3531, 0.40180000000000005, 0.5009, 0.1769, 0.3627, 0.1577, 0.1831, 0.07200000000000001, 0.22460000000000002, 0.6388, 0.35350000000000004, 0.6548, 0.48260000000000003, 0.1514, 0.38420000000000004, 0.0766, 0.257, 0.1922, 0.2373, 0.2862]),\n",
              "       ...,\n",
              "       list([0.7704000000000001, 1.1338, 1.1025, 1.0991, 0.2758, 0.1406, -0.022500000000000003, -0.0224, 0.028, 0.26890000000000003, 1.1011, 0.1198, 0.3945, 0.8075, 0.6866, 0.47440000000000004, 0.1277, 0.0631, 0.35100000000000003, 0.3674, 0.436, 0.194, 0.4625, 0.1661, 0.5086, 0.7015, 0.2972, 0.8011, 0.060500000000000005, 0.3266, 0.8508, 0.5608000000000001, 0.9395, 0.3895, 1.0127, 1.4893, 0.7771, 0.5346000000000001, 0.38620000000000004, 0.4329, 0.8892, 0.7759, 0.867, 0.44220000000000004, 0.4334, 0.11230000000000001, 0.3612, 0.6237, 0.6990000000000001, 0.8982, 0.5222, 0.8259000000000001, 0.2927, 0.5407000000000001, 0.6843, 0.6758000000000001, 0.6181, 0.8824000000000001, 0.7419, 0.9951000000000001, 0.5914, 0.6132000000000001, 0.5976, 0.11, 0.010400000000000001, -0.0038, 0.006500000000000001, 0.15660000000000002]),\n",
              "       list([0.45220000000000005, 0.8404, 0.9064000000000001, 0.8682000000000001, 1.1043, 0.5782, 0.6483, 0.1336, 0.197, 0.2, 1.322, 0.1379, 0.0441, 0.0762, 0.0234, 0.009300000000000001, 0.0223, 0.5459, 0.0362, -0.0011, 0.0316, 0.0315, 0.041100000000000005, 0.0135, 0.0152, 0.049300000000000004, 0.0213, 0.0341, 0.048400000000000006, 0.2803, 0.0263, 0.0279, 0.19010000000000002, 0.6147, 0.2775, 0.2553, 0.2192, 1.1259000000000001, 0.016300000000000002, 0.0038, 0.008700000000000001, 0.5634, 0.018500000000000003, 0.024, 0.0488, 0.0083, 0.14780000000000001, 0.0717, 0.0553, 0.0443, 0.0994, 0.0395, 0.08310000000000001, 0.1246, 0.1393, 0.6284000000000001, 0.9312, 0.1188, 0.08420000000000001, 0.1998, 0.096, -0.0019, 0.0083, 0.2553, 0.3582, 0.0132, 0.107, 0.0829]),\n",
              "       list([1.0254, 1.9580000000000002, 1.4929000000000001, 1.1275, 0.5416000000000001, 0.064, 0.032600000000000004, 0.0198, 0.046400000000000004, 0.0, 0.025400000000000002, 0.025400000000000002, 0.012700000000000001, 0.0478, 0.0281, -0.0078000000000000005, 0.0685, 0.016900000000000002, 0.11280000000000001, 0.463, 1.6875, 0.2731, 0.08, 0.0745, 0.042, 0.0424, 0.031200000000000002, 0.47340000000000004, 1.5075, 0.3773, 0.056100000000000004, 0.178, 0.013000000000000001, 0.592, 1.9295, 0.366, 1.6327, 1.2543, 1.1280000000000001, 1.8842, 0.041100000000000005, 0.012, 0.059000000000000004, 0.2343, 0.0456, 0.0407, 0.0021000000000000003, 0.011300000000000001, 0.0009000000000000001, 0.0466, 0.0732, 0.0337, -0.01, 0.0, 0.0059, 0.09670000000000001, 0.0359, 0.0004, 0.0055000000000000005, 0.0011, 0.0057, 0.0004, -0.009300000000000001, 0.0057, 0.0031000000000000003, 0.4606, 0.8652000000000001, 0.3725])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bFovITd4U2b"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Recurrent layer\n",
        "model.add(LSTM(128, input_shape=(68, 3), return_sequences=True, \n",
        "               dropout=0.1, recurrent_dropout=0.1))\n",
        "\n",
        "# Fully connected layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl0cGCrxA_9D"
      },
      "source": [
        "model.fit(x_train, y_train, epochs = 3, validation_data=(x_dev, y_dev))"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBvrJST5pY7g"
      },
      "source": [
        "# evaluation score\n",
        "def MCRMSE(y_true, y_pred):\n",
        "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=(0, 1))\n",
        "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=-1)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmcrfPaGpcvM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}